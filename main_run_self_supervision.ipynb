{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of main-run-self-supervision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s275090/MLDL-First-Person-Action-Recognition/blob/main/main_run_self_supervision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1PXD2NL4Nxf"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjRb9K14hW_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e60470-aecd-48d1-e056-0e1e74273c41"
      },
      "source": [
        "!pip3 install 'tensorboardX' "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBdMq5aF4YHP"
      },
      "source": [
        "**Import Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Db3Jwa4tG-q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "ab2eb4ab-74d7-411d-b508-5763d770d07b"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "# To download the repository https://drive.google.com/drive/folders/1_NAcoR0UGH1eLsiWMOx_Py8yeAocknA2?usp=sharing\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = 'drive/My Drive/ego-rnn/'\n",
        "os.chdir(path)\n",
        "cwd = os.getcwd()\n",
        "print(\"Current dir: \"+cwd)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c9051e9dc417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/My Drive/ego-rnn/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    290\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhQZjOdN4Unu"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3mf6kG2OBPO"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n",
        "from tensorboardX import SummaryWriter\n",
        "from makeDatasetRGB import *\n",
        "from makeDatasetMmaps import *\n",
        "from MyConvLSTMCell import *\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRoOMlKgKWEZ"
      },
      "source": [
        "class MyMotionSegCell(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size=1, stride=1, padding=0):\n",
        "        super(MyMotionSegCell, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.ms_conv = nn.Conv2d(512, 100, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.ms_fc = nn.Linear(100 * 7 * 7, 2 * 7 * 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(x)\n",
        "        x = self.ms_conv(x)\n",
        "        x = x.view(x.size(0),100*7*7)\n",
        "        x = self.ms_fc(x)\n",
        "        x = x.view(x.size(0),2,7,7)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs6-NQYvMAsK"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from resnetMod import *\n",
        "\n",
        "class convLSTMModel(nn.Module):\n",
        "    def __init__(self, num_classes=61, mem_size=512):\n",
        "        super(convLSTMModel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.resNet = resnet34(False, True)\n",
        "        self.mem_size = mem_size\n",
        "        self.weight_softmax = self.resNet.fc.weight\n",
        "        self.lstm_cell = MyConvLSTMCell(512, mem_size)\n",
        "        self.ms_cell = MyMotionSegCell()\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc = nn.Linear(mem_size, self.num_classes)\n",
        "        self.classifier = nn.Sequential(self.dropout, self.fc)\n",
        "\n",
        "    def forward(self, inputVariable, CAM = False, MS = False):\n",
        "        state = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n",
        "                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n",
        "        feats_ms = []\n",
        "\n",
        "        for t in range(inputVariable.size(0)):\n",
        "            logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n",
        "\n",
        "            if MS: \n",
        "              feats_ms.append(self.ms_cell(feature_conv))\n",
        "\n",
        "            if CAM:\n",
        "              bz, nc, h, w = feature_conv.size()\n",
        "              feature_conv1 = feature_conv.view(bz, nc, h*w)\n",
        "              probs, idxs = logit.sort(1, True)\n",
        "              class_idx = idxs[:, 0]\n",
        "              cam = torch.bmm(self.weight_softmax[class_idx].unsqueeze(1), feature_conv1)\n",
        "              attentionMAP = F.softmax(cam.squeeze(1), dim=1)\n",
        "              attentionMAP = attentionMAP.view(attentionMAP.size(0), 1, 7, 7)\n",
        "              attentionFeat = feature_convNBN * attentionMAP.expand_as(feature_conv)\n",
        "              state = self.lstm_cell(attentionFeat, state)\n",
        "            else:\n",
        "              state = self.lstm_cell(feature_conv, state)\n",
        "        \n",
        "        if MS:\n",
        "          feats_ms = torch.stack(feats_ms, 0)\n",
        "\n",
        "        feats1 = self.avgpool(state[1]).view(state[1].size(0), -1)\n",
        "        feats = self.classifier(feats1)\n",
        "        return feats, feats_ms, feats1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6NIyeyZDWOM"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV7T6n-Iqecv"
      },
      "source": [
        "data_dir = \"GTEA61/processed_frames2\"\n",
        "out_dir = 'experiments'\n",
        "model_folder = os.path.join('./', out_dir, 'self-supervised', 'ConvLSMT-Attention','16frm')  # Dir for saving models and log files\n",
        "\n",
        "user_train = ['S1','S3','S4']\n",
        "user_val = ['S2']\n",
        "trainBatchSize = 64\n",
        "valBatchSize = 64\n",
        "memSize = 512\n",
        "num_classes = 61\n",
        "\n",
        "frame = 16\n",
        "seqLen = frame\n",
        "\n",
        "MS = True\n",
        "CAM = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05aii3lCDt_4"
      },
      "source": [
        "**Prepare Dataset and Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzBtJm6BsiHA"
      },
      "source": [
        "# Data loader\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224)])\n",
        "\n",
        "vid_seq_train = makeDatasetMmaps(data_dir, user_train, frame,\n",
        "                            spatial_transform=spatial_transform, normalize=normalize, seqLen=seqLen, fmt='.png')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\n",
        "                        shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "vid_seq_val = makeDataset(data_dir, user_val, frame,\n",
        "                            spatial_transform=Compose([Scale(256), CenterCrop(224), ToTensor(), normalize]),\n",
        "                            seqLen=seqLen, fmt='.png')\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize,\n",
        "                        shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "valInstances = vid_seq_val.__len__()\n",
        "trainInstances = vid_seq_train.__len__()\n",
        "\n",
        "print('Number of samples in the dataset: training = {} | validation = {}'.format(trainInstances, valInstances))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRPNRIHtBP2T"
      },
      "source": [
        "**Stage 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDFIBy-CBPS5"
      },
      "source": [
        "stage1_dict = (out_dir + '/rgb/ConvLSMT-Attention/16frame/stage1/model_rgb_state_dict.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4dU_oN43NX2"
      },
      "source": [
        "**Stage 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kULTC6MA5TSC"
      },
      "source": [
        "**Set Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EaY--DY7a-f"
      },
      "source": [
        "numEpochs = 150\n",
        "lr1 =1e-5 #1e-4\n",
        "decay_step = [25, 75]\n",
        "decay_factor = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNoKjb1v6Ey4"
      },
      "source": [
        "# Create the dir\n",
        "if os.path.exists(model_folder):\n",
        "    print('Directory {} exists!'.format(model_folder))\n",
        "    #sys.exit()\n",
        "#os.makedirs(model_folder)\n",
        "\n",
        "# Log files\n",
        "writer = SummaryWriter(model_folder)\n",
        "train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n",
        "train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n",
        "val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n",
        "val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QW6v8Fk5Ysd"
      },
      "source": [
        "**Prepare Network and Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o1qNkv63MgT"
      },
      "source": [
        "train_params = []\n",
        "\n",
        "model = convLSTMModel(num_classes=num_classes, mem_size=memSize)\n",
        "\n",
        "model.load_state_dict(torch.load(stage1_dict),strict=False)\n",
        "model.train(False)\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "#\n",
        "for params in model.resNet.layer4[0].conv1.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.resNet.layer4[0].conv2.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.resNet.layer4[1].conv1.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.resNet.layer4[1].conv2.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.resNet.layer4[2].conv1.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "#\n",
        "for params in model.resNet.layer4[2].conv2.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "#\n",
        "for params in model.resNet.fc.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "model.resNet.layer4[0].conv1.train(True)\n",
        "model.resNet.layer4[0].conv2.train(True)\n",
        "model.resNet.layer4[1].conv1.train(True)\n",
        "model.resNet.layer4[1].conv2.train(True)\n",
        "model.resNet.layer4[2].conv1.train(True)\n",
        "model.resNet.layer4[2].conv2.train(True)\n",
        "model.resNet.fc.train(True)\n",
        "\n",
        "for params in model.lstm_cell.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.classifier.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.ms_cell.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "model.lstm_cell.train(True)\n",
        "model.ms_cell.train(True)\n",
        "\n",
        "model.classifier.train(True)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK9_SZbs5hMB"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v9OXl9mLw80"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=4e-5, eps=1e-4)\n",
        "\n",
        "optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step,\n",
        "                                                        gamma=decay_factor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoF8FCyj5jnh"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ButMUOcS3qvI"
      },
      "source": [
        "train_iter = 0\n",
        "min_accuracy = 0\n",
        "loss_mmaps = []\n",
        "\n",
        "\n",
        "for epoch in range(numEpochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_loss_mmap = 0\n",
        "    numCorrTrain = 0\n",
        "    trainSamples = 0\n",
        "    iterPerEpoch = 0\n",
        "    model.lstm_cell.train(True)\n",
        "    model.ms_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    writer.add_scalar('lr', optimizer_fn.param_groups[0]['lr'], epoch+1)\n",
        "\n",
        "    model.resNet.layer4[0].conv1.train(True)\n",
        "    model.resNet.layer4[0].conv2.train(True)\n",
        "    model.resNet.layer4[1].conv1.train(True)\n",
        "    model.resNet.layer4[1].conv2.train(True)\n",
        "    model.resNet.layer4[2].conv1.train(True)\n",
        "    model.resNet.layer4[2].conv2.train(True)\n",
        "    model.resNet.fc.train(True)\n",
        "\n",
        "    for i, (inputs, mmaps, targets) in enumerate(train_loader):\n",
        "        train_iter += 1\n",
        "        iterPerEpoch += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "        inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n",
        "        labelVariable = Variable(targets.cuda())\n",
        "        trainSamples += inputs.size(0)\n",
        "\n",
        "        output_label, output_mmaps, _ = model(inputVariable,CAM, MS)\n",
        "        \n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "        \n",
        "        if MS:\n",
        "          mmapsVariable = Variable(mmaps.cuda())\n",
        "          mmapsVariable = torch.squeeze(mmapsVariable)\n",
        "          output_mmaps = output_mmaps.permute(1, 2, 0, 3, 4)\n",
        "          loss+=loss_fn(output_mmaps, mmapsVariable.long())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += (predicted == targets.cuda()).sum()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_loss_mmap += loss_fn(output_mmaps, mmapsVariable.long()).item()\n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    avg_loss_mmap = epoch_loss_mmap/iterPerEpoch\n",
        "    loss_mmaps.append(avg_loss_mmap)\n",
        "    trainAccuracy = (numCorrTrain.item() / trainSamples) * 100\n",
        "\n",
        "    print('Train: Epoch = {} | Loss = {} | Accuracy = {}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    \n",
        "    train_log_loss.write('Train Loss after {} epochs = {}\\n'.format(epoch + 1, avg_loss))\n",
        "    train_log_acc.write('Train Accuracy after {} epochs = {}%\\n'.format(epoch + 1, trainAccuracy))\n",
        "    writer.add_scalar('train/epoch_loss', avg_loss, epoch+1)\n",
        "    writer.add_scalar('train/accuracy', trainAccuracy, epoch+1)\n",
        "    \n",
        "    if (epoch+1) % 1 == 0:\n",
        "        model.train(False)\n",
        "        model.ms_cell.train(False)\n",
        "        val_loss_epoch = 0\n",
        "        val_iter = 0\n",
        "        val_samples = 0\n",
        "        numCorr = 0\n",
        "        for j, (inputs, targets) in enumerate(val_loader):\n",
        "            val_iter += 1\n",
        "            val_samples += inputs.size(0)\n",
        "            inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n",
        "            labelVariable = Variable(targets.cuda(non_blocking=True))\n",
        "            output_label, _, _ = model(inputVariable, CAM, False)\n",
        "            val_loss = loss_fn(output_label, labelVariable)\n",
        "            val_loss_epoch += val_loss.item()\n",
        "            _, predicted = torch.max(output_label.data, 1)\n",
        "            numCorr += (predicted == targets.cuda()).sum()\n",
        "        val_accuracy = (numCorr.item() / val_samples) * 100\n",
        "        avg_val_loss = val_loss_epoch / val_iter\n",
        "        print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "        writer.add_scalar('val/epoch_loss', avg_val_loss, epoch + 1)\n",
        "        writer.add_scalar('val/accuracy', val_accuracy, epoch + 1)\n",
        "        val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))\n",
        "        val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))\n",
        "        \n",
        "        if val_accuracy > min_accuracy:\n",
        "            save_path_model = (model_folder + '/model_rgb_state_dict.pth')\n",
        "            torch.save(model.state_dict(), save_path_model)\n",
        "            min_accuracy = val_accuracy\n",
        "    \n",
        "    # Step the scheduler\n",
        "    optim_scheduler.step()\n",
        "    \n",
        "\n",
        "train_log_loss.close()\n",
        "train_log_acc.close()\n",
        "val_log_acc.close()\n",
        "val_log_loss.close()\n",
        "writer.export_scalars_to_json(model_folder + \"/all_scalars.json\")\n",
        "writer.close()\n",
        "\n",
        "print('Best accuracy after {} epochs = {}'.format(epoch, min_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}