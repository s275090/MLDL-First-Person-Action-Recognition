{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of main-run-self-supervision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s275090/MLDL-First-Person-Action-Recognition/blob/main/main_run_self_supervision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1PXD2NL4Nxf"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjRb9K14hW_l"
      },
      "source": [
        "!pip3 install 'tensorboardX' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBdMq5aF4YHP"
      },
      "source": [
        "**Import Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Db3Jwa4tG-q"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "# To download the repository https://drive.google.com/drive/folders/1_NAcoR0UGH1eLsiWMOx_Py8yeAocknA2?usp=sharing\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = 'drive/My Drive/ego-rnn/'\n",
        "os.chdir(path)\n",
        "cwd = os.getcwd()\n",
        "print(\"Current dir: \"+cwd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhQZjOdN4Unu"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3mf6kG2OBPO"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
        "                                RandomHorizontalFlip)\n",
        "from tensorboardX import SummaryWriter\n",
        "from makeDatasetRGB import *\n",
        "from makeDatasetMmaps import *\n",
        "from MyConvLSTMCell import *\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRoOMlKgKWEZ"
      },
      "source": [
        "class MyMotionSegCell(nn.Module):\n",
        "\n",
        "    def __init__(self, kernel_size=1, stride=1, padding=0):\n",
        "        super(MyMotionSegCell, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.ms_conv = nn.Conv2d(512, 100, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.ms_fc = nn.Linear(100 * 7 * 7, 2 * 7 * 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(x)\n",
        "        x = self.ms_conv(x)\n",
        "        x = x.view(x.size(0),100*7*7)\n",
        "        x = self.ms_fc(x)\n",
        "        x = x.view(x.size(0),2,7,7)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs6-NQYvMAsK"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "from resnetMod import *\n",
        "\n",
        "class convLSTMModel(nn.Module):\n",
        "    def __init__(self, num_classes=61, mem_size=512):\n",
        "        super(convLSTMModel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.resNet = resnet34(False, True)\n",
        "        self.mem_size = mem_size\n",
        "        self.weight_softmax = self.resNet.fc.weight\n",
        "        self.lstm_cell = MyConvLSTMCell(512, mem_size)\n",
        "        self.ms_cell = MyMotionSegCell()\n",
        "        self.avgpool = nn.AvgPool2d(7)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc = nn.Linear(mem_size, self.num_classes)\n",
        "        self.classifier = nn.Sequential(self.dropout, self.fc)\n",
        "\n",
        "    def forward(self, inputVariable, CAM = False, MS = False):\n",
        "        state = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n",
        "                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n",
        "        feats_ms = []\n",
        "\n",
        "        for t in range(inputVariable.size(0)):\n",
        "            logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n",
        "\n",
        "            if MS: \n",
        "              feats_ms.append(self.ms_cell(feature_conv))\n",
        "\n",
        "            if CAM:\n",
        "              bz, nc, h, w = feature_conv.size()\n",
        "              feature_conv1 = feature_conv.view(bz, nc, h*w)\n",
        "              probs, idxs = logit.sort(1, True)\n",
        "              class_idx = idxs[:, 0]\n",
        "              cam = torch.bmm(self.weight_softmax[class_idx].unsqueeze(1), feature_conv1)\n",
        "              attentionMAP = F.softmax(cam.squeeze(1), dim=1)\n",
        "              attentionMAP = attentionMAP.view(attentionMAP.size(0), 1, 7, 7)\n",
        "              attentionFeat = feature_convNBN * attentionMAP.expand_as(feature_conv)\n",
        "              state = self.lstm_cell(attentionFeat, state)\n",
        "            else:\n",
        "              state = self.lstm_cell(feature_conv, state)\n",
        "        \n",
        "        if MS:\n",
        "          feats_ms = torch.stack(feats_ms, 0)\n",
        "\n",
        "        feats1 = self.avgpool(state[1]).view(state[1].size(0), -1)\n",
        "        feats = self.classifier(feats1)\n",
        "        return feats, feats_ms, feats1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6NIyeyZDWOM"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV7T6n-Iqecv"
      },
      "source": [
        "data_dir = \"GTEA61/processed_frames2\"\n",
        "out_dir = 'experiments'\n",
        "model_folder = os.path.join('./', out_dir, 'self-supervised', 'ConvLSMT-Attention','16frm')  # Dir for saving models and log files\n",
        "\n",
        "user_train = ['S1','S3','S4']\n",
        "user_val = ['S2']\n",
        "trainBatchSize = 64\n",
        "valBatchSize = 64\n",
        "memSize = 512\n",
        "num_classes = 61\n",
        "\n",
        "frame = 16\n",
        "seqLen = frame\n",
        "\n",
        "MS = True\n",
        "CAM = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05aii3lCDt_4"
      },
      "source": [
        "**Prepare Dataset and Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzBtJm6BsiHA"
      },
      "source": [
        "# Data loader\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224)])\n",
        "\n",
        "vid_seq_train = makeDatasetMmaps(data_dir, user_train, frame,\n",
        "                            spatial_transform=spatial_transform, normalize=normalize, seqLen=seqLen, fmt='.png')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\n",
        "                        shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "vid_seq_val = makeDataset(data_dir, user_val, frame,\n",
        "                            spatial_transform=Compose([Scale(256), CenterCrop(224), ToTensor(), normalize]),\n",
        "                            seqLen=seqLen, fmt='.png')\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize,\n",
        "                        shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "valInstances = vid_seq_val.__len__()\n",
        "trainInstances = vid_seq_train.__len__()\n",
        "\n",
        "print('Number of samples in the dataset: training = {} | validation = {}'.format(trainInstances, valInstances))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRPNRIHtBP2T"
      },
      "source": [
        "**Stage 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDFIBy-CBPS5"
      },
      "source": [
        "stage1_dict = (out_dir + '/rgb/ConvLSMT-Attention/16frame/stage1/model_rgb_state_dict.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4dU_oN43NX2"
      },
      "source": [
        "**Stage 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kULTC6MA5TSC"
      },
      "source": [
        "**Set Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EaY--DY7a-f"
      },
      "source": [
        "numEpochs = 150\n",
        "lr1 =1e-5 #1e-4\n",
        "decay_step = [25, 75]\n",
        "decay_factor = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNoKjb1v6Ey4"
      },
      "source": [
        "# Create the dir\n",
        "if os.path.exists(model_folder):\n",
        "    print('Directory {} exists!'.format(model_folder))\n",
        "    #sys.exit()\n",
        "#os.makedirs(model_folder)\n",
        "\n",
        "# Log files\n",
        "writer = SummaryWriter(model_folder)\n",
        "train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n",
        "train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n",
        "val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n",
        "val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QW6v8Fk5Ysd"
      },
      "source": [
        "**Prepare Network and Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o1qNkv63MgT"
      },
      "source": [
        "train_params = []\n",
        "\n",
        "model = convLSTMModel(num_classes=num_classes, mem_size=memSize)\n",
        "\n",
        "model.load_state_dict(torch.load(stage1_dict),strict=False)\n",
        "model.train(False)\n",
        "for params in model.parameters():\n",
        "    params.requires_grad = False\n",
        "#\n",
        "for params in model.resNet.layer4[0].conv1.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.resNet.layer4[0].conv2.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.resNet.layer4[1].conv1.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.resNet.layer4[1].conv2.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.resNet.layer4[2].conv1.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "#\n",
        "for params in model.resNet.layer4[2].conv2.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "#\n",
        "for params in model.resNet.fc.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "model.resNet.layer4[0].conv1.train(True)\n",
        "model.resNet.layer4[0].conv2.train(True)\n",
        "model.resNet.layer4[1].conv1.train(True)\n",
        "model.resNet.layer4[1].conv2.train(True)\n",
        "model.resNet.layer4[2].conv1.train(True)\n",
        "model.resNet.layer4[2].conv2.train(True)\n",
        "model.resNet.fc.train(True)\n",
        "\n",
        "for params in model.lstm_cell.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.classifier.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "for params in model.ms_cell.parameters():\n",
        "    params.requires_grad = True\n",
        "    train_params += [params]\n",
        "\n",
        "model.lstm_cell.train(True)\n",
        "model.ms_cell.train(True)\n",
        "\n",
        "model.classifier.train(True)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK9_SZbs5hMB"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v9OXl9mLw80"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=4e-5, eps=1e-4)\n",
        "\n",
        "optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step,\n",
        "                                                        gamma=decay_factor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoF8FCyj5jnh"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ButMUOcS3qvI"
      },
      "source": [
        "train_iter = 0\n",
        "min_accuracy = 0\n",
        "loss_mmaps = []\n",
        "\n",
        "\n",
        "for epoch in range(numEpochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_loss_mmap = 0\n",
        "    numCorrTrain = 0\n",
        "    trainSamples = 0\n",
        "    iterPerEpoch = 0\n",
        "    model.lstm_cell.train(True)\n",
        "    model.ms_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "    writer.add_scalar('lr', optimizer_fn.param_groups[0]['lr'], epoch+1)\n",
        "\n",
        "    model.resNet.layer4[0].conv1.train(True)\n",
        "    model.resNet.layer4[0].conv2.train(True)\n",
        "    model.resNet.layer4[1].conv1.train(True)\n",
        "    model.resNet.layer4[1].conv2.train(True)\n",
        "    model.resNet.layer4[2].conv1.train(True)\n",
        "    model.resNet.layer4[2].conv2.train(True)\n",
        "    model.resNet.fc.train(True)\n",
        "\n",
        "    for i, (inputs, mmaps, targets) in enumerate(train_loader):\n",
        "        train_iter += 1\n",
        "        iterPerEpoch += 1\n",
        "        optimizer_fn.zero_grad()\n",
        "        inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n",
        "        labelVariable = Variable(targets.cuda())\n",
        "        trainSamples += inputs.size(0)\n",
        "\n",
        "        output_label, output_mmaps, _ = model(inputVariable,CAM, MS)\n",
        "        \n",
        "        loss = loss_fn(output_label, labelVariable)\n",
        "        \n",
        "        if MS:\n",
        "          mmapsVariable = Variable(mmaps.cuda())\n",
        "          mmapsVariable = torch.squeeze(mmapsVariable)\n",
        "          output_mmaps = output_mmaps.permute(1, 2, 0, 3, 4)\n",
        "          loss+=loss_fn(output_mmaps, mmapsVariable.long())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_fn.step()\n",
        "        _, predicted = torch.max(output_label.data, 1)\n",
        "        numCorrTrain += (predicted == targets.cuda()).sum()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_loss_mmap += loss_fn(output_mmaps, mmapsVariable.long()).item()\n",
        "    avg_loss = epoch_loss/iterPerEpoch\n",
        "    avg_loss_mmap = epoch_loss_mmap/iterPerEpoch\n",
        "    loss_mmaps.append(avg_loss_mmap)\n",
        "    trainAccuracy = (numCorrTrain.item() / trainSamples) * 100\n",
        "\n",
        "    print('Train: Epoch = {} | Loss = {} | Accuracy = {}'.format(epoch+1, avg_loss, trainAccuracy))\n",
        "    \n",
        "    train_log_loss.write('Train Loss after {} epochs = {}\\n'.format(epoch + 1, avg_loss))\n",
        "    train_log_acc.write('Train Accuracy after {} epochs = {}%\\n'.format(epoch + 1, trainAccuracy))\n",
        "    writer.add_scalar('train/epoch_loss', avg_loss, epoch+1)\n",
        "    writer.add_scalar('train/accuracy', trainAccuracy, epoch+1)\n",
        "    \n",
        "    if (epoch+1) % 1 == 0:\n",
        "        model.train(False)\n",
        "        model.ms_cell.train(False)\n",
        "        val_loss_epoch = 0\n",
        "        val_iter = 0\n",
        "        val_samples = 0\n",
        "        numCorr = 0\n",
        "        for j, (inputs, targets) in enumerate(val_loader):\n",
        "            val_iter += 1\n",
        "            val_samples += inputs.size(0)\n",
        "            inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n",
        "            labelVariable = Variable(targets.cuda(non_blocking=True))\n",
        "            output_label, _, _ = model(inputVariable, CAM, False)\n",
        "            val_loss = loss_fn(output_label, labelVariable)\n",
        "            val_loss_epoch += val_loss.item()\n",
        "            _, predicted = torch.max(output_label.data, 1)\n",
        "            numCorr += (predicted == targets.cuda()).sum()\n",
        "        val_accuracy = (numCorr.item() / val_samples) * 100\n",
        "        avg_val_loss = val_loss_epoch / val_iter\n",
        "        print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "        writer.add_scalar('val/epoch_loss', avg_val_loss, epoch + 1)\n",
        "        writer.add_scalar('val/accuracy', val_accuracy, epoch + 1)\n",
        "        val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))\n",
        "        val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))\n",
        "        \n",
        "        if val_accuracy > min_accuracy:\n",
        "            save_path_model = (model_folder + '/model_rgb_state_dict.pth')\n",
        "            torch.save(model.state_dict(), save_path_model)\n",
        "            min_accuracy = val_accuracy\n",
        "    \n",
        "    # Step the scheduler\n",
        "    optim_scheduler.step()\n",
        "    \n",
        "\n",
        "train_log_loss.close()\n",
        "train_log_acc.close()\n",
        "val_log_acc.close()\n",
        "val_log_loss.close()\n",
        "writer.export_scalars_to_json(model_folder + \"/all_scalars.json\")\n",
        "writer.close()\n",
        "\n",
        "print('Best accuracy after {} epochs = {}'.format(epoch, min_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}